import streamlit as st
import google.generativeai as genai
from PIL import Image
import datetime

# --- 1. ã‚¢ãƒ—ãƒªã®åˆæœŸè¨­å®š ---
st.set_page_config(page_title="AIæ•°å­¦å°‚å±ã‚³ãƒ¼ãƒ", page_icon="ğŸ“", layout="centered")

# --- ãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«Bã®è‚: ã€Œèª°ãŒã€å‹‰å¼·ã—ã¦ã„ã‚‹ã‹ ---
if "student_name" not in st.session_state:
    st.session_state.student_name = "ã‚²ã‚¹ãƒˆ"

st.title("ğŸ“ é«˜æ ¡æ•°å­¦ AIå°‚å±ã‚³ãƒ¼ãƒ")
st.caption("æ•™ç§‘æ›¸ã®å†…å®¹ã‚’ã€Œå®Œç’§ã€ã«ç†è§£ã—ã‚ˆã†ã€‚ç­”ãˆã¯æ•™ãˆã¾ã›ã‚“ã€ä¸€ç·’ã«è§£ãã¾ã™ã€‚")

# --- 2. ä¼šè©±å±¥æ­´ã¨åˆ©ç”¨ã‚«ã‚¦ãƒ³ãƒˆã®ä¿å­˜å ´æ‰€ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# â˜… ãƒ‡ãƒãƒƒã‚°ç”¨: æœ€å¾Œã«ä½¿ã‚ã‚ŒãŸãƒ¢ãƒ‡ãƒ«åã‚’ä¿å­˜ã™ã‚‹å¤‰æ•° â˜…
if "last_used_model" not in st.session_state:
    st.session_state.last_used_model = "ã¾ã å›ç­”ã—ã¦ã„ã¾ã›ã‚“"

# èµ¤å­—é˜²æ­¢ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
if "pro_usage_count" not in st.session_state:
    st.session_state.pro_usage_count = 0
if "last_reset_date" not in st.session_state:
    st.session_state.last_reset_date = datetime.date.today()

if st.session_state.last_reset_date != datetime.date.today():
    st.session_state.pro_usage_count = 0
    st.session_state.last_reset_date = datetime.date.today()

# ãƒªã‚»ãƒƒãƒˆç”¨ã‚­ãƒ¼ç®¡ç†
if "uploader_key" not in st.session_state:
    st.session_state["uploader_key"] = 0
if "form_key_index" not in st.session_state:
    st.session_state.form_key_index = 0

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆè¨­å®šï¼‰ ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    st.session_state.student_name = st.text_input("ã‚ãªãŸã®ãŠåå‰", value=st.session_state.student_name)
    
    api_key = ""
    try:
        if "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
    except:
        pass
    
    if not api_key:
        input_key = st.text_input("Gemini APIã‚­ãƒ¼", type="password")
        if input_key: api_key = input_key.strip()
    
    st.markdown("---")
    st.info(f"ã‚ˆã†ã“ãã€{st.session_state.student_name}ã•ã‚“ã€‚\nç„¦ã‚‰ãšåŸºç¤ã‹ã‚‰å›ºã‚ã¦ã„ãã¾ã—ã‚‡ã†ã€‚")
    st.markdown("---")
    
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", type="primary"):
        st.session_state.messages = []
        st.session_state.last_used_model = "ãƒªã‚»ãƒƒãƒˆæ¸ˆã¿" # ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºã‚‚ãƒªã‚»ãƒƒãƒˆ
        st.rerun()

    # â˜…â˜…â˜… ãƒ‡ãƒãƒƒã‚°ç”¨è¡¨ç¤ºã‚¨ãƒªã‚¢ï¼ˆå®Œæˆç‰ˆã§ã¯ã“ã“ã‚’æ¶ˆã™ã ã‘ï¼ï¼‰ â˜…â˜…â˜…
    st.markdown("---")
    st.caption("ğŸ› ï¸ é–‹ç™ºè€…ç”¨ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
    if "pro" in st.session_state.last_used_model:
        st.error(f"Last Model: {st.session_state.last_used_model}") # Proãªã‚‰èµ¤è‰²ã§è­¦å‘Šã£ã½ãè¡¨ç¤º
    else:
        st.success(f"Last Model: {st.session_state.last_used_model}") # Flashãªã‚‰ç·‘è‰²ã§è¡¨ç¤º
    
    st.write(f"Pro Count: {st.session_state.pro_usage_count} / 15")

# --- 4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾© ---
system_instruction = f"""
ã‚ãªãŸã¯æ—¥æœ¬ã®é€²å­¦æ ¡ã§æ•™ãˆã‚‹ã€éå¸¸ã«å„ªç§€ã§å¿è€å¼·ã„æ•°å­¦æ•™å¸«ã§ã™ã€‚
ç›¸æ‰‹ã¯é«˜æ ¡ç”Ÿã®ã€Œ{st.session_state.student_name}ã€ã•ã‚“ã§ã™ã€‚

ã€æŒ‡å°ã®çµ¶å¯¾ãƒ«ãƒ¼ãƒ«ã€‘
1. **ã‚½ã‚¯ãƒ©ãƒ†ã‚¹å¼æŒ‡å°:** ç­”ãˆã‚’æ•™ãˆãšã€å•ã„ã‹ã‘ã§å°ãã“ã¨ã€‚
2. **æ•™ç§‘æ›¸æº–æ‹ :** é«˜æ ¡æ•°å­¦ã®ç¯„å›²å†…ã§è§£èª¬ã™ã‚‹ã“ã¨ã€‚
3. **å„ªã—ã•ã¨æ‰¿èª:** å¦å®šã›ãšã€è¤’ã‚ã¦ä¼¸ã°ã™ã“ã¨ã€‚
4. **å½¢å¼:** æ•°å¼ã¯LaTeXå½¢å¼ï¼ˆ$ãƒãƒ¼ã‚¯ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚

ã€ç”»åƒã«ã¤ã„ã¦ã€‘
å•é¡Œã‚’èª­ã¿å–ã‚Šã€æ–¹é‡ã®ãƒ’ãƒ³ãƒˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚
"""

# --- 5. ãƒãƒ£ãƒƒãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        content = message["content"]
        if isinstance(content, dict):
            if "image" in content:
                st.image(content["image"], width=300)
            if "text" in content:
                st.markdown(content["text"])
        else:
            st.markdown(content)

# --- 6. AIå¿œç­”ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒ‡ãƒãƒƒã‚°æƒ…å ±ä¿å­˜æ©Ÿèƒ½ä»˜ãï¼‰ ---
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    if not api_key:
        st.warning("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    
    genai.configure(api_key=api_key)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        
        # å±¥æ­´æ§‹ç¯‰
        history_for_ai = []
        for m in st.session_state.messages[:-1]:
            if m["role"] != "system":
                text_content = ""
                if isinstance(m["content"], dict):
                    text_content = m["content"].get("text", "")
                else:
                    text_content = str(m["content"])
                history_for_ai.append({"role": m["role"], "parts": [text_content]})

        current_msg = st.session_state.messages[-1]["content"]
        content_to_send = []
        if isinstance(current_msg, dict):
            if "text" in current_msg: content_to_send.append(current_msg["text"])
            if "image" in current_msg: content_to_send.append(current_msg["image"])
        else:
            content_to_send.append(current_msg)

        # â˜…â˜…â˜… æˆ¦ç•¥çš„ãƒ¢ãƒ‡ãƒ«å„ªå…ˆé †ä½ â˜…â˜…â˜…
        PRIORITY_MODELS = [
            "gemini-2.5-flash",       # ãƒ¡ã‚¤ãƒ³
            "gemini-1.5-pro",         # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            "gemini-2.0-flash"        # äºˆå‚™
        ]
        
        PRO_LIMIT_PER_DAY = 15

        success = False
        active_model = None
        last_error = None
        
        # è©¦è¡Œé–¢æ•°
        def try_generate(model_name):
            retry_model = genai.GenerativeModel(model_name, system_instruction=system_instruction)
            chat = retry_model.start_chat(history=history_for_ai)
            return chat.send_message(content_to_send, stream=True)

        for model_name in PRIORITY_MODELS:
            if "pro" in model_name and st.session_state.pro_usage_count >= PRO_LIMIT_PER_DAY:
                continue

            try:
                response = try_generate(model_name)
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        response_placeholder.markdown(full_response)
                
                success = True
                active_model = model_name
                
                if "pro" in model_name:
                    st.session_state.pro_usage_count += 1
                
                break
            except Exception:
                continue
        
        if not success:
            if st.session_state.pro_usage_count >= PRO_LIMIT_PER_DAY:
                st.warning("âš ï¸ æœ¬æ—¥ã®ã€Œé«˜åº¦ãªå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ï¼ˆProï¼‰ã€ã®åˆ©ç”¨ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ç¾åœ¨ã¯å›ç·šãŒæ··ã¿åˆã£ã¦ãŠã‚Šã€æ˜æ—¥ã¾ãŸã”åˆ©ç”¨ã„ãŸã ã‘ã¾ã™ã€‚")
            else:
                try:
                    fetched_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                    for model_name in fetched_models:
                        if "pro" not in model_name:
                            try:
                                response = try_generate(model_name)
                                for chunk in response:
                                    if chunk.text:
                                        full_response += chunk.text
                                        response_placeholder.markdown(full_response)
                                success = True
                                active_model = model_name
                                break
                            except:
                                continue
                except:
                    pass
                
                if success:
                    st.session_state.messages.append({"role": "model", "content": full_response})
                    # â˜… ãƒ‡ãƒãƒƒã‚°æƒ…å ±ä¿å­˜ â˜…
                    st.session_state.last_used_model = active_model
                    st.rerun()
                else:
                    st.error("âŒ ç¾åœ¨ã‚¢ã‚¯ã‚»ã‚¹ãŒé›†ä¸­ã—ã¦ãŠã‚Šå¿œç­”ã§ãã¾ã›ã‚“ã€‚")

        if success:
            st.session_state.messages.append({"role": "model", "content": full_response})
            # â˜… ãƒ‡ãƒãƒƒã‚°æƒ…å ±ä¿å­˜ â˜…
            st.session_state.last_used_model = active_model
            print(f"Used Model: {active_model}, Pro Count Today: {st.session_state.pro_usage_count}")
            st.rerun()

# --- 7. å…¥åŠ›ã‚¨ãƒªã‚¢ ---
if not (st.session_state.messages and st.session_state.messages[-1]["role"] == "user"):
    
    current_key = st.session_state.form_key_index
    uploader_key = f"uploader_{current_key}"

    input_type = st.radio("å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰", ["âŒ¨ï¸ ãƒ†ã‚­ã‚¹ãƒˆã§è³ªå•", "ğŸ“¸ ç”»åƒã§è³ªå•"], horizontal=True, label_visibility="collapsed")

    if input_type == "âŒ¨ï¸ ãƒ†ã‚­ã‚¹ãƒˆã§è³ªå•":
        with st.form(key=f'text_form_{current_key}'):
            user_text = st.text_area("ã“ã“ã«å…¥åŠ›...", height=100, placeholder="ä¾‹ï¼šæ•™ç§‘æ›¸ã®ã“ã®å®šç¾©ãŒã‚ˆãåˆ†ã‹ã‚Šã¾ã›ã‚“...")
            submit_btn = st.form_submit_button("é€ä¿¡", type="primary")
            
            if submit_btn and user_text:
                st.session_state.messages.append({"role": "user", "content": user_text})
                st.session_state.form_key_index += 1
                st.rerun()

    elif input_type == "ğŸ“¸ ç”»åƒã§è³ªå•":
        st.info("æ•™ç§‘æ›¸ã‚„å•é¡Œé›†ã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        img_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "jpeg"], key=uploader_key)
        img_comment = st.text_input("è£œè¶³ï¼ˆä»»æ„ï¼‰", placeholder="ä¾‹ï¼š(2)ã®è§£èª¬ã‚’ãŠé¡˜ã„ã—ã¾ã™", key=f"comment_{current_key}")
        
        if st.button("ç”»åƒã§è³ªå•ã™ã‚‹", type="primary"):
            if img_file:
                image_data = Image.open(img_file)
                text_part = img_comment if img_comment else "ã“ã®å•é¡Œã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚"
                content_to_save = {"image": image_data, "text": text_part}
                
                st.session_state.messages.append({"role": "user", "content": content_to_save})
                st.session_state.form_key_index += 1
                st.rerun()
            else:
                st.warning("ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
