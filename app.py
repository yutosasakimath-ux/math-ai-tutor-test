import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- 1. ã‚¢ãƒ—ãƒªã®åˆæœŸè¨­å®š ---
st.set_page_config(page_title="AIæ•°å­¦å°‚å±ã‚³ãƒ¼ãƒ", page_icon="ğŸ“", layout="centered")

# --- ãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«Bã®è‚: ã€Œèª°ãŒã€å‹‰å¼·ã—ã¦ã„ã‚‹ã‹ ---
if "student_name" not in st.session_state:
    st.session_state.student_name = "ã‚²ã‚¹ãƒˆ"

st.title("ğŸ“ é«˜æ ¡æ•°å­¦ AIå°‚å±ã‚³ãƒ¼ãƒ")
st.caption("ç­”ãˆã¯æ•™ãˆã¾ã›ã‚“ã€‚ã€Œè§£ãæ–¹ã€ã‚’ä¸€ç·’ã«è€ƒãˆã¾ã—ã‚‡ã†ã€‚")

# --- 2. ä¼šè©±å±¥æ­´ã®ä¿å­˜å ´æ‰€ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# ãƒªã‚»ãƒƒãƒˆç”¨ã‚­ãƒ¼ç®¡ç†
if "uploader_key" not in st.session_state:
    st.session_state["uploader_key"] = 0
if "form_key_index" not in st.session_state:
    st.session_state["form_key_index"] = 0

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆè¨­å®šãƒ»è¨ºæ–­ï¼‰ ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # ç”Ÿå¾’æƒ…å ±ã®å…¥åŠ›
    st.session_state.student_name = st.text_input("ã‚ãªãŸã®ãŠåå‰", value=st.session_state.student_name)
    
    # APIã‚­ãƒ¼è¨­å®š
    api_key = ""
    try:
        if "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("âœ… èªè¨¼æ¸ˆã¿ (Secrets)")
    except:
        pass
    
    if not api_key:
        input_key = st.text_input("Gemini APIã‚­ãƒ¼", type="password")
        if input_key: api_key = input_key.strip()
    
    st.markdown("---")
    
    # â˜…â˜…â˜… æ¥ç¶šè¨ºæ–­ãƒœã‚¿ãƒ³ â˜…â˜…â˜…
    with st.expander("ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"):
        if st.button("ğŸ”‘ æ¥ç¶šãƒ†ã‚¹ãƒˆãƒ»åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ç¢ºèª"):
            if not api_key:
                st.error("ã¾ãšã¯APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                try:
                    genai.configure(api_key=api_key)
                    st.write("Googleã¸ã®æ¥ç¶šã‚’è©¦ã¿ã¦ã„ã¾ã™...")
                    
                    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
                    available_models = []
                    for m in genai.list_models():
                        if 'generateContent' in m.supported_generation_methods:
                            available_models.append(m.name)
                    
                    if available_models:
                        st.success(f"âœ… æ¥ç¶šæˆåŠŸï¼åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ ({len(available_models)}å€‹)")
                        st.code("\n".join(available_models))
                        st.info("ã“ã®ãƒªã‚¹ãƒˆã«ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•çš„ã«ä½¿ç”¨ã—ã¾ã™ã€‚")
                    else:
                        st.warning("âš ï¸ æ¥ç¶šã§ãã¾ã—ãŸãŒã€ãƒãƒ£ãƒƒãƒˆã«ä½¿ç”¨ã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚APIã‚­ãƒ¼ã®ç¨®é¡ï¼ˆVertex AIç”¨ãªã©ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        
                except Exception as e:
                    st.error(f"âŒ æ¥ç¶šå¤±æ•—: {e}")
                    st.caption("APIã‚­ãƒ¼ãŒé–“é•ã£ã¦ã„ã‚‹ã‹ã€Google AI Studioã§APIãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

    st.markdown("---")
    
    st.info(f"ã‚ˆã†ã“ãã€{st.session_state.student_name}ã•ã‚“ã€‚\nä»Šæ—¥ã‚‚ä¸€ç·’ã«é ‘å¼µã‚Šã¾ã—ã‚‡ã†ï¼")

    st.markdown("---")
    
    # æ‰‹å‹•ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", type="primary"):
        st.session_state.messages = []
        st.rerun()

# --- 4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾©ï¼ˆã‚½ã‚¯ãƒ©ãƒ†ã‚¹å¼ãƒ»æ•™è‚²ç‰¹åŒ–ï¼‰ ---
system_instruction = f"""
ã‚ãªãŸã¯ãƒ—ãƒ­ã®æ•°å­¦å®¶åº­æ•™å¸«ã§ã™ã€‚ç›¸æ‰‹ã¯é«˜æ ¡ç”Ÿã®ã€Œ{st.session_state.student_name}ã€ã•ã‚“ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’å³æ ¼ã«å®ˆã£ã¦ãã ã•ã„ã€‚

ã€çµ¶å¯¾ãƒ«ãƒ¼ãƒ«ï¼šã‚½ã‚¯ãƒ©ãƒ†ã‚¹å¼æŒ‡å°ã€‘
1. **ç­”ãˆã‚’ã™ãã«æ•™ãˆãªã„ã“ã¨ã€‚** ç”Ÿå¾’ãŒè‡ªåˆ†ã§æ°—ã¥ãã‚ˆã†ã«å°ã„ã¦ãã ã•ã„ã€‚
2. ç”Ÿå¾’ã‹ã‚‰è³ªå•ã‚„ç”»åƒã®é€ä¿¡ãŒã‚ã£ãŸå ´åˆã€ã€Œã©ã“ã¾ã§åˆ†ã‹ã£ãŸï¼Ÿã€ã€Œä½•ãŒåˆ†ã‹ã‚‰ãªã„ï¼Ÿã€ã¨å„ªã—ãå•ã„ã‹ã‘ã¦ãã ã•ã„ã€‚
3. æ±ºã—ã¦ä¸Šã‹ã‚‰ç›®ç·šã«ãªã‚‰ãšã€ä¼´èµ°ã™ã‚‹ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚
4. æ•°å¼ã¯LaTeXå½¢å¼ï¼ˆ$ãƒãƒ¼ã‚¯ï¼‰ã‚’ä½¿ã£ã¦ç¶ºéº—ã«è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚
5. è§£èª¬ãŒé•·ããªã‚Šã™ããªã„ã‚ˆã†ã«ã€ä¼šè©±ã®ã‚­ãƒ£ãƒƒãƒãƒœãƒ¼ãƒ«ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚

ã€ç”»åƒãŒé€ã‚‰ã‚ŒãŸå ´åˆã€‘
- ç”»åƒå†…ã®å•é¡Œã‚’èª­ã¿å–ã‚Šã€ã„ããªã‚Šè§£ç­”ã‚’æ›¸ãã®ã§ã¯ãªãã€ã€Œã“ã®å•é¡Œã®ã©ã®æ–¹é‡ã§è¿·ã£ã¦ã‚‹ï¼Ÿã€ã¨ãƒ’ãƒ³ãƒˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚
"""

# --- 5. ãƒãƒ£ãƒƒãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        content = message["content"]
        if isinstance(content, dict):
            if "image" in content:
                st.image(content["image"], width=300)
            if "text" in content:
                st.markdown(content["text"])
        else:
            st.markdown(content)

# --- 6. AIå¿œç­”ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆè‡ªå·±ä¿®å¾©æ©Ÿèƒ½ä»˜ãï¼‰ ---
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    if not api_key:
        st.warning("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    
    # è¨­å®š
    genai.configure(api_key=api_key)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        
        # å±¥æ­´ã®æ§‹ç¯‰
        history_for_ai = []
        for m in st.session_state.messages[:-1]:
            if m["role"] != "system":
                text_content = ""
                if isinstance(m["content"], dict):
                    text_content = m["content"].get("text", "")
                else:
                    text_content = str(m["content"])
                history_for_ai.append({"role": m["role"], "parts": [text_content]})

        # æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        current_msg = st.session_state.messages[-1]["content"]
        content_to_send = []
        if isinstance(current_msg, dict):
            if "text" in current_msg: content_to_send.append(current_msg["text"])
            if "image" in current_msg: content_to_send.append(current_msg["image"])
        else:
            content_to_send.append(current_msg)

        # â˜…â˜…â˜… æˆ¦ç•¥çš„ãƒ¢ãƒ‡ãƒ«å„ªå…ˆé †ä½ â˜…â˜…â˜…
        # ã‚ãªãŸã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ä½¿ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã‹ã‚‰ã€
        # ã€Œè³¢ã•ã€ã¨ã€Œã‚³ã‚¹ãƒˆã€ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„é †ã«ä¸¦ã¹ã¦ã„ã¾ã™ã€‚
        PRIORITY_MODELS = [
            "gemini-2.5-flash",       # ç¬¬1å€™è£œ: æœ€æ–°ãƒ»é«˜é€Ÿãƒ»é«˜ã‚³ã‚¹ãƒ‘ï¼ˆæœ¬å‘½ï¼‰
            "gemini-2.0-flash",       # ç¬¬2å€™è£œ: å®‰å®šã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            "gemini-2.5-pro",         # ç¬¬3å€™è£œ: è¶…é«˜æ€§èƒ½ã ãŒã‚³ã‚¹ãƒˆé«˜ã‚ï¼ˆåˆ‡ã‚Šæœ­ï¼‰
            "gemini-2.0-flash-lite"   # ç¬¬4å€™è£œ: è¶…ä½ã‚³ã‚¹ãƒˆï¼ˆç·Šæ€¥ç”¨ï¼‰
        ]
        
        success = False
        last_error = None
        
        # è©¦è¡Œé–¢æ•°
        def try_generate(model_name):
            retry_model = genai.GenerativeModel(model_name, system_instruction=system_instruction)
            chat = retry_model.start_chat(history=history_for_ai)
            return chat.send_message(content_to_send, stream=True)

        # A. å„ªå…ˆãƒªã‚¹ãƒˆã§ãƒˆãƒ©ã‚¤
        active_model = None
        for model_name in PRIORITY_MODELS:
            try:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«å¯¾ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆã‚’è©¦ã¿ã‚‹
                # (ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã ã‘ã§ãªãã€å®Ÿéš›ã«send_messageã—ã¦ã‚¨ãƒ©ãƒ¼ãŒå‡ºãªã„ã‹ç¢ºèª)
                response = try_generate(model_name)
                
                # æˆåŠŸã—ãŸã‚‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        response_placeholder.markdown(full_response)
                
                success = True
                active_model = model_name
                break
            except Exception:
                # ã“ã®ãƒ¢ãƒ‡ãƒ«ãŒãƒ€ãƒ¡ãªã‚‰æ¬¡ã¸
                continue
        
        # B. å„ªå…ˆãƒªã‚¹ãƒˆãŒå…¨æ»…ã—ãŸå ´åˆã€ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã€Œæœ¬å½“ã«ä½¿ãˆã‚‹ãƒªã‚¹ãƒˆã€ã‚’å–å¾—ã—ã¦å†ãƒˆãƒ©ã‚¤ï¼ˆè‡ªå·±ä¿®å¾©ï¼‰
        if not success:
            try:
                fetched_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                for model_name in fetched_models:
                    try:
                        response = try_generate(model_name)
                        for chunk in response:
                            if chunk.text:
                                full_response += chunk.text
                                response_placeholder.markdown(full_response)
                        success = True
                        active_model = model_name
                        break
                    except Exception as e:
                        last_error = e
                        continue
            except Exception as e:
                last_error = e

        if success:
            st.session_state.messages.append({"role": "model", "content": full_response})
            # ãƒ‡ãƒãƒƒã‚°ç”¨ã«å®Ÿéš›ã«ä½¿ã‚ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆæœ¬ç•ªã§ã¯æ¶ˆã—ã¦ã‚‚OKï¼‰
            print(f"Used Model: {active_model}")
            st.rerun()
        else:
            st.error("âŒ ã‚¨ãƒ©ãƒ¼: AIã‚·ã‚¹ãƒ†ãƒ ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            with st.expander("è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"):
                st.write(f"Last Error: {last_error}")

# --- 7. å…¥åŠ›ã‚¨ãƒªã‚¢ ---
if not (st.session_state.messages and st.session_state.messages[-1]["role"] == "user"):
    
    current_key = st.session_state["form_key_index"]
    uploader_key = f"uploader_{current_key}"

    input_type = st.radio("å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰", ["âŒ¨ï¸ ãƒ†ã‚­ã‚¹ãƒˆã§è³ªå•", "ğŸ“¸ ç”»åƒã§è³ªå•"], horizontal=True, label_visibility="collapsed")

    if input_type == "âŒ¨ï¸ ãƒ†ã‚­ã‚¹ãƒˆã§è³ªå•":
        with st.form(key=f'text_form_{current_key}'):
            user_text = st.text_area("ã“ã“ã«å…¥åŠ›...", height=100, placeholder="ä¾‹ï¼šäºŒæ¬¡é–¢æ•°ã®é ‚ç‚¹ã®æ±‚ã‚æ–¹ãŒã‚ã‹ã‚Šã¾ã›ã‚“ã€‚")
            submit_btn = st.form_submit_button("é€ä¿¡", type="primary")
            
            if submit_btn and user_text:
                st.session_state.messages.append({"role": "user", "content": user_text})
                st.session_state["form_key_index"] += 1
                st.rerun()

    elif input_type == "ğŸ“¸ ç”»åƒã§è³ªå•":
        st.info("åˆ†ã‹ã‚‰ãªã„å•é¡Œã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        img_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "jpeg"], key=uploader_key)
        img_comment = st.text_input("è£œè¶³ï¼ˆä»»æ„ï¼‰", placeholder="ä¾‹ï¼š(2)ãŒã‚ã‹ã‚Šã¾ã›ã‚“", key=f"comment_{current_key}")
        
        if st.button("ç”»åƒã§è³ªå•ã™ã‚‹", type="primary"):
            if img_file:
                image_data = Image.open(img_file)
                text_part = img_comment if img_comment else "ã“ã®å•é¡Œã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚"
                content_to_save = {"image": image_data, "text": text_part}
                
                st.session_state.messages.append({"role": "user", "content": content_to_save})
                st.session_state["form_key_index"] += 1
                st.rerun()
            else:
                st.warning("ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
