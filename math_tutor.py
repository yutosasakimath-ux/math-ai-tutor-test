import streamlit as st
import google.generativeai as genai

# --- 1. ã‚¢ãƒ—ãƒªã®åˆæœŸè¨­å®š ---
st.set_page_config(page_title="æ•°å­¦AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼", page_icon="ğŸ“")

st.title("ğŸ“ é«˜æ ¡æ•°å­¦ AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼")
st.caption("Gemini 2.5 Flash æ­è¼‰ã€‚æœ€æ–°AIãŒã‚ãªãŸã®å­¦ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ï¼")

# --- 2. ä¼šè©±å±¥æ­´ã®ä¿å­˜å ´æ‰€ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("å…ˆç”Ÿç”¨ç®¡ç†ç”»é¢")
    
    # APIã‚­ãƒ¼è¨­å®š
    api_key = ""
    try:
        if "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("âœ… èªè¨¼æ¸ˆã¿ï¼ˆã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ¼ä½¿ç”¨ä¸­ï¼‰")
    except:
        pass

    if not api_key:
        input_key = st.text_input("Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›", type="password")
        if input_key:
            api_key = input_key.strip()
    
    st.markdown("---")

    # æ©Ÿèƒ½1ï¼šä¼šè©±ãƒªã‚»ãƒƒãƒˆ
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹", type="primary"):
        st.session_state.messages = []
        st.rerun()

    st.markdown("---")
    
    # æ©Ÿèƒ½2ï¼šé¡é¡Œè¨­å®šï¼†å‡ºé¡Œãƒœã‚¿ãƒ³
    st.write("### ğŸ”„ é¡é¡Œã®ä½œæˆ")
    
    # å•é¡Œæ•°ã®æŒ‡å®šï¼ˆ1ã€œ5å•ï¼‰
    num_questions = st.number_input("ä½œæˆã™ã‚‹å•é¡Œæ•°", min_value=1, max_value=5, value=1)
    
    if st.button("é¡é¡Œã‚’å‡ºé¡Œã™ã‚‹"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã¨ã—ã¦ã€æŒ‡å®šã•ã‚ŒãŸå•é¡Œæ•°ã‚’åŸ‹ã‚è¾¼ã‚€
        prompt_text = f"""
        ã€æ•™å¸«ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€‘
        ç›´å‰ã®ã‚„ã‚Šå–ã‚Šã§æ‰±ã£ãŸå•é¡Œã¨ã€ŒåŒã˜å˜å…ƒã€ã€ŒåŒã˜é›£æ˜“åº¦ã€ã®é¡é¡Œã‚’ã€{num_questions}å•ã€‘ä½œæˆã—ã¦ãã ã•ã„ã€‚
        æ•°å€¤ã‚’å¤‰ãˆã‚‹ã ã‘ã§ãªãã€æœ¬è³ªçš„ãªç†è§£ã‚’è©¦ã™å•é¡Œã«ã—ã¦ãã ã•ã„ã€‚
        ã¾ã è§£èª¬ã¯ã›ãšã€å•é¡Œã®ã¿ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
        """
        # å±¥æ­´ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": prompt_text})
        st.rerun()
    
    st.markdown("---")
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆPDFç”¨ã®æŒ‡ç¤ºãªã©ã¯å‰Šé™¤ã—ã€å…ƒã«æˆ»ã—ã¾ã—ãŸï¼‰
    system_instruction = """
    ã‚ãªãŸã¯æ—¥æœ¬ã®é«˜æ ¡ã®è¦ªåˆ‡ã§å„ªç§€ãªæ•°å­¦æ•™å¸«ã§ã™ã€‚
    ç”Ÿå¾’ã‹ã‚‰ã®æ•°å­¦ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
    
    ã€æŒ‡å°ã®ãƒ«ãƒ¼ãƒ«ã€‘
    1. **ã™ãã«æœ€çµ‚çš„ãªæ­£è§£ã‚’æ•™ãˆãªã„ã“ã¨**ã€‚
    2. ç”Ÿå¾’ãŒè‡ªåŠ›ã§è§£ã‘ã‚‹ã‚ˆã†ã«ã€æ®µéšçš„ãªãƒ’ãƒ³ãƒˆã‚„ã€è€ƒãˆæ–¹ã®é“ç­‹ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
    3. ç”Ÿå¾’ãŒé–“é•ãˆã¦ã„ã‚‹å ´åˆã¯ã€å¦å®šã›ãšã€Œæƒœã—ã„ï¼ã€ã€Œã“ã“ã‚’ç¢ºèªã—ã¦ã¿ã¦ã€ã¨åŠ±ã¾ã—ã¦ãã ã•ã„ã€‚
    4. æ•°å¼ã¯LaTeXå½¢å¼ï¼ˆ$ãƒãƒ¼ã‚¯ã§å›²ã‚€ï¼‰ã‚’ä½¿ã£ã¦ç¶ºéº—ã«è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚
    5. è§£èª¬ã¯é«˜æ ¡ç”Ÿã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„å¹³æ˜“ãªè¨€è‘‰ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
    6. ã€Œé¡é¡Œã€ã‚’æ±‚ã‚ã‚‰ã‚ŒãŸã‚‰ã€æŒ‡å®šã•ã‚ŒãŸæ•°ã®ç·´ç¿’å•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    """

# --- 4. ãƒ¢ãƒ‡ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
if api_key:
    genai.configure(api_key=api_key)
    
    try:
        target_model_name = "gemini-2.5-flash"
        
        model = genai.GenerativeModel(
            model_name=target_model_name,
            system_instruction=system_instruction
        )

        # é–‹ç™ºè€…ç”¨ãƒ¢ãƒ‡ãƒ«è¡¨ç¤º
        st.sidebar.divider()
        st.sidebar.caption("ğŸ› ï¸ Developer Info")
        st.sidebar.info(f"ğŸ¤– Active Model:\n`{target_model_name}`")

    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

# --- 5. éå»ã®ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤º ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. AIå¿œç­”ãƒ­ã‚¸ãƒƒã‚¯ ---
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    
    if not api_key:
        st.warning("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«APIã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ãã ã•ã„")
        st.stop()

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        
        try:
            chat_history_for_ai = [
                {"role": m["role"], "parts": [m["content"]]} 
                for m in st.session_state.messages 
                if m["role"] != "system"
            ]
            
            chat = model.start_chat(history=chat_history_for_ai)
            
            last_msg = st.session_state.messages[-1]["content"]
            response = chat.send_message(last_msg, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    response_placeholder.markdown(full_response)
            
            st.session_state.messages.append({"role": "model", "content": full_response})
            st.rerun()

        except Exception as e:
            err_msg = str(e)
            if "429" in err_msg:
                 st.error("âš ï¸ åˆ©ç”¨åˆ¶é™ï¼ˆ429ã‚¨ãƒ©ãƒ¼ï¼‰ã€‚å°‘ã—æ™‚é–“ã‚’ç½®ã„ã¦ãã ã•ã„ã€‚")
            elif "404" in err_msg:
                 st.error(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target_model_name}")
            else:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# --- 7. å…¥åŠ›ã‚¨ãƒªã‚¢ ---
if not (st.session_state.messages and st.session_state.messages[-1]["role"] == "user"):
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›..."):
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()
